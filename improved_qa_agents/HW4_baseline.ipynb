{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f3fe1f",
   "metadata": {},
   "source": [
    "# HW4: QA Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c91ec1",
   "metadata": {},
   "source": [
    "## Dependencies and LLM Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42689839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==1.0.5\n",
    "# !pip install langchain-core\n",
    "# !pip install langchain-community\n",
    "# !pip install faiss-cpu\n",
    "# !pip install kagglehub\n",
    "device = \"cuda\"  # \"cpu\" or \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af723c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the list of countries we are using (with their official languages)\n",
    "# Feel free to use it in your code\n",
    "list_of_countries = {}\n",
    "with open(\"countries_with_languages.tsv\", \"r\"  ) as f:\n",
    "    for line in f.readlines():\n",
    "        country, langs = line.strip().split(\"\\t\")\n",
    "        list_of_countries[country] = langs.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c06a7d",
   "metadata": {},
   "source": [
    "### Choice 1: OpenAI API\n",
    "\n",
    "The notebook's implementation is based on this.\n",
    "Feel free to change the model, and please keep track of your usage on the \"Usage\" page on [LiteLLM API webpage](https://ai-gateway.andrew.cmu.edu/ui/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65e4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import getpass, os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "openai_model_id = \"gpt-5\"\n",
    "openai_embmodel_id = \"azure/text-embedding-3-small\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=openai_model_id,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=\"https://ai-gateway.andrew.cmu.edu/\"\n",
    ")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=openai_embmodel_id,\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    base_url='https://ai-gateway.andrew.cmu.edu/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b00ca",
   "metadata": {},
   "source": [
    "### Choice 2: Hugging Face Models\n",
    "\n",
    "You may also use Hugging Face models without API credits if you have available GPU resource. You might have to the change prompt templates according to your model choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1bc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-huggingface text-generation transformers google-search-results \n",
    "# !pip install numexpr langchainhub sentencepiece sentence-transformers jinja2 bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf0fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-05 10:15:07.691824: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764929707.719849  399834 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764929707.731784  399834 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-05 10:15:07.968242: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import getpass, os, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")\n",
    "hgf_model_id = \"Qwen/Qwen3-0.6B\"\n",
    "hgf_embmodel_id = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "# Select device and dtype\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "# Build HF generation pipeline on GPU when available\n",
    "tokenizer = AutoTokenizer.from_pretrained(hgf_model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    hgf_model_id,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "gen_pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=dtype,\n",
    ")\n",
    "\n",
    "hgf_model = HuggingFacePipeline(pipeline=gen_pipe)\n",
    "hgf_llm = ChatHuggingFace(llm=hgf_model)\n",
    "\n",
    "# Place sentence-transformers embeddings on GPU when available\n",
    "hgf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=hgf_embmodel_id,\n",
    "    model_kwargs={\"device\": device}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a37cbe",
   "metadata": {},
   "source": [
    "## Handling different type of questions\n",
    "\n",
    "Implement the answer formatting and extraction for each question type. You may change the prompt to fit your processing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e242dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a4262",
   "metadata": {},
   "source": [
    "### ðŸ—ºï¸Global Trekker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bce1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_trekker_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert in world geography and cultural geography. Given a descriptive paragraph, infer the most likely country and city with high precision.\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"\n",
    "Read the paragraph and extract:\n",
    "- Country: use the full official country name (e.g., \"United States\", not \"USA\").\n",
    "- City: a specific city if clearly indicated by clues (landmarks, neighborhoods, transit lines, local foods, dialects). If not identifiable, write \"Unknown\".\n",
    "\n",
    "Strict output format (no explanations):\n",
    "[Country], [City]\n",
    "\n",
    "Guidelines:\n",
    "- Prefer unique cues (local transit names, street names, postal formats, phone codes, currency, cuisine, sports clubs).\n",
    "- If multiple cities fit, pick the single most likely one.\n",
    "- If the paragraph is generic or only country-level, return \"Unknown\" for city.\n",
    "- Do not include any extra text besides the bracketed pair.\n",
    "\n",
    "Examples:\n",
    "Input: \"We walked along the Arno past the Ponte Vecchio before climbing to Piazzale Michelangelo.\"\n",
    "Output: [Italy], [Florence]\n",
    "\n",
    "Input: \"A red double-decker bus passed by the Thames near Westminster Abbey and Big Ben.\"\n",
    "Output: [United Kingdom], [London]\n",
    "\n",
    "Input: \"We grabbed Primanti's near the confluence of the Allegheny and Monongahela.\"\n",
    "Output: [United States], [Pittsburgh]\n",
    "\n",
    "Input: \"I toured the Old Town and the Royal Mile before seeing the castle on the hill.\"\n",
    "Output: [United Kingdom], [Edinburgh]\n",
    "\n",
    "Input: \"We enjoyed maple syrup and poutine while skating on a canal in winter.\"\n",
    "Output: [Canada], [Ottawa]\n",
    "\"\"\"},\n",
    "]\n",
    "\n",
    "global_trekker = create_agent(model=llm, tools=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85342fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_global_trekker_answer(response: str) -> tuple[str, str]:\n",
    "    # TODO: Extract the country and city from the response\n",
    "    # return country, city\n",
    "    import re\n",
    "    \n",
    "    # Look for pattern [country], [city] or variations\n",
    "    # Try to find content within brackets first\n",
    "    bracket_pattern = r'\\[([^\\]]+)\\]\\s*,\\s*\\[([^\\]]+)\\]'\n",
    "    match = re.search(bracket_pattern, response)\n",
    "    \n",
    "    if match:\n",
    "        country = match.group(1).strip()\n",
    "        city = match.group(2).strip()\n",
    "        return country, city\n",
    "    \n",
    "    # Fallback: look for two items separated by comma\n",
    "    # Often LLMs will say something like \"United States, Pittsburgh\"\n",
    "    lines = response.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        # Skip lines that are too long (likely explanations)\n",
    "        if len(line) > 100:\n",
    "            continue\n",
    "        # Look for comma-separated values\n",
    "        if ',' in line:\n",
    "            parts = line.split(',')\n",
    "            if len(parts) >= 2:\n",
    "                country = parts[0].strip().strip('[]\"\\'')\n",
    "                city = parts[1].strip().strip('[]\"\\'')\n",
    "                # Clean up common prefixes\n",
    "                for prefix in ['The answer is', 'Answer:', 'Location:', 'Country:', 'City:']:\n",
    "                    country = country.replace(prefix, '').strip()\n",
    "                    city = city.replace(prefix, '').strip()\n",
    "                return country, city\n",
    "    \n",
    "    # Last resort: return empty strings\n",
    "    return \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5210d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AAA', 'BBB')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test run your extration function before using it in the main loop!\n",
    "extract_global_trekker_answer(\"AAA, BBB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ab9c1",
   "metadata": {},
   "source": [
    "### ðŸ½ï¸Culinary Detective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a359380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "def gather_recipe_data(kaggledataset: str) -> list[str]:\n",
    "    dataset_path = kagglehub.dataset_download(kaggledataset)\n",
    "    df = pd.read_csv(f\"{dataset_path}/Receipes from around the world.csv\", encoding='latin-1')\n",
    "    \n",
    "    # Process the dataframe to list of text entries for retrieval\n",
    "    # Format each recipe as structured text for better retrieval\n",
    "    recipes = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Create a readable text representation of each recipe\n",
    "        recipe_parts = []\n",
    "        for col in df.columns:\n",
    "            value = row[col]\n",
    "            # Skip NaN values and format nicely\n",
    "            if pd.notna(value) and str(value).strip():\n",
    "                recipe_parts.append(f\"{col}: {value}\")\n",
    "        \n",
    "        # Join all parts into a single text entry\n",
    "        recipe_text = \". \".join(recipe_parts)\n",
    "        recipes.append(recipe_text)\n",
    "    \n",
    "    return recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3b33c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain.tools import tool\n",
    "\n",
    "recipes = gather_recipe_data(\"prajwaldongre/collection-of-recipes-around-the-world\")\n",
    "docs = [Document(page_content=recipe) for recipe in recipes]\n",
    "vector = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vector.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53c0b0",
   "metadata": {},
   "source": [
    "## RAG Tool\n",
    "I created the following:\n",
    "- a folder to store embeddings and faiss index\n",
    "- a rag pipeline file\n",
    "- a file that exposes the rag pipeline as a tool. \n",
    "- I am importing the tool in here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cafce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/codespace/nlp_assignments/improved_qa_agents/rag_system/rag_pipeline.py:13: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from rag_system.rag_pipeline import CulinaryRAG\n",
    "\n",
    "# Load the RAG engine and retriever\n",
    "rag = CulinaryRAG()\n",
    "retriever = rag.load_index()  # returns vectorstore.as_retriever()\n",
    "\n",
    "@tool\n",
    "def retrieve_culinary_context(query: str):\n",
    "    \"\"\"\n",
    "    Retrieves culinary information relevant to country/region origin detection.\n",
    "    Takes a descriptive query (ingredients, cooking method, spices) and performs vector retrieval.\n",
    "    \"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44bd8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_recipes(query: str):\n",
    "  \"\"\"\n",
    "  Retrieves recipes based on a search query.\n",
    "  \"\"\"\n",
    "  return retriever.invoke(query)\n",
    "\n",
    "culinary_detective_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"\n",
    "You are an expert culinary anthropologist. From ingredients and a short description, identify the country and the SPECIFIC region within that country where the dish is most associated.\n",
    "\n",
    "You can consult a retrieval tool bound to this agent (retrieve_culinary_context). Use it when helpful; otherwise reason from your knowledge of ingredients, techniques, and named dishes.\n",
    "\"\"\"},\n",
    "    {\"role\": \"human\", \"content\": \"\"\"\n",
    "Task:\n",
    "Return ONLY a single line in the exact format: [Country], [Region]\n",
    "- Country: full official name (e.g., \"United States\", not \"USA\").\n",
    "- Region: a specific intra-country region (e.g., North, South, East, West, Central, Northeast, etc.).\n",
    "- Use \"All\" only if the dish is truly nationwide.\n",
    "- If no region is identifiable, write \"Unknown\".\n",
    "- Do NOT include any explanation before or after the bracketed answer.\n",
    "\n",
    "Cues to consider:\n",
    "- Ingredients (grains, staple flours, spice blends), cooking methods, named dishes, iconic sides.\n",
    "- Example mappings:\n",
    "  * Brazil: pÃ£o de queijo / tapioca flour / queijo minas â†’ [Brazil], [South]\n",
    "  * Japan: sushi / rice vinegar / tempura â†’ [Japan], [All]\n",
    "  * India: dosa / idli / coconut â†’ [India], [South]; naan / paneer / tandoor â†’ [India], [North]\n",
    "  * Ethiopia: teff / injera / wat / berbere â†’ [Ethiopia], [Unknown]\n",
    "  * China: dim sum â†’ [China], [South]; hot pot (Sichuan/Chongqing-style) â†’ [China], [West]\n",
    "  * Thailand: khao soi â†’ [Thailand], [North]; som tam â†’ [Thailand], [Northeast]\n",
    "\n",
    "Few-shot examples:\n",
    "Input: \"Fermented teff flatbread served with spicy stews (wat) and berbere.\"\n",
    "Output: [Ethiopia], [Unknown]\n",
    "\n",
    "Input: \"Cheese bread made with tapioca starch, typical with churrasco in the south.\"\n",
    "Output: [Brazil], [South]\n",
    "\n",
    "Input: \"Batter of rice and urad dal, steamed into soft cakes, served with coconut chutney.\"\n",
    "Output: [India], [South]\n",
    "\n",
    "Input: \"Assorted small bites with tea in bamboo steamers, hallmark of Cantonese cuisine.\"\n",
    "Output: [China], [South]\n",
    "\n",
    "Now produce ONLY the answer for the current input as [Country], [Region].\n",
    "\"\"\"},\n",
    "]\n",
    "\n",
    "culinary_detective = create_agent(model=llm, tools=[retrieve_culinary_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "921d5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [SystemMessage(content='\\nYou are an expert culinary anthropologist. From ingredients and a short description, identify the country and the SPECIFIC region within that country where the dish is most associated.\\n\\nYou can consult a retrieval tool bound to this agent (retrieve_culinary_context). Use it when helpful; otherwise reason from your knowledge of ingredients, techniques, and named dishes.\\n', additional_kwargs={}, response_metadata={}, id='99af5be1-15bc-4026-a914-01f3f79d64f0'), HumanMessage(content='\\nTask:\\nReturn ONLY a single line in the exact format: [Country], [Region]\\n- Country: full official name (e.g., \"United States\", not \"USA\").\\n- Region: a specific intra-country region (e.g., North, South, East, West, Central, Northeast, etc.).\\n- Use \"All\" only if the dish is truly nationwide.\\n- If no region is identifiable, write \"Unknown\".\\n- Do NOT include any explanation before or after the bracketed answer.\\n\\nCues to consider:\\n- Ingredients (grains, staple flours, spice blends), cooking methods, named dishes, iconic sides.\\n- Example mappings:\\n  * Brazil: pÃ£o de queijo / tapioca flour / queijo minas â†’ [Brazil], [South]\\n  * Japan: sushi / rice vinegar / tempura â†’ [Japan], [All]\\n  * India: dosa / idli / coconut â†’ [India], [South]; naan / paneer / tandoor â†’ [India], [North]\\n  * Ethiopia: teff / injera / wat / berbere â†’ [Ethiopia], [Unknown]\\n  * China: dim sum â†’ [China], [South]; hot pot (Sichuan/Chongqing-style) â†’ [China], [West]\\n  * Thailand: khao soi â†’ [Thailand], [North]; som tam â†’ [Thailand], [Northeast]\\n\\nFew-shot examples:\\nInput: \"Fermented teff flatbread served with spicy stews (wat) and berbere.\"\\nOutput: [Ethiopia], [Unknown]\\n\\nInput: \"Cheese bread made with tapioca starch, typical with churrasco in the south.\"\\nOutput: [Brazil], [South]\\n\\nInput: \"Batter of rice and urad dal, steamed into soft cakes, served with coconut chutney.\"\\nOutput: [India], [South]\\n\\nInput: \"Assorted small bites with tea in bamboo steamers, hallmark of Cantonese cuisine.\"\\nOutput: [China], [South]\\n\\nNow produce ONLY the answer for the current input as [Country], [Region].\\n', additional_kwargs={}, response_metadata={}, id='0d9c18b1-19a4-47b0-afd4-51388163a040'), HumanMessage(content='The dish is spicy, coconut-based, and served with rice.', additional_kwargs={}, response_metadata={}, id='8c5e87e0-a929-417d-b603-3c18478fe09c'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 576, 'total_tokens': 602, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-CjN904cUNSw2HIQujac0AthGaOadA', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--d8e66d78-3b5d-42bf-b1f9-386b476883d5-0', tool_calls=[{'name': 'retrieve_culinary_context', 'args': {'query': 'spicy, coconut-based dish served with rice'}, 'id': 'call_FWe3tDCKPwc8PVAzFnQkSLya', 'type': 'tool_call'}], usage_metadata={'input_tokens': 576, 'output_tokens': 26, 'total_tokens': 602, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='RecipeId: 455303\\nName: Coconut Curry Rice\\nAuthorId: 177443\\nAuthorName: BecR2400\\nCookTime: PT20M\\nPrepTime: PT10M\\nTotalTime: PT30M\\nDatePublished: 2011-05-06T14:28:00Z\\nDescription: Fragrant yellow rice with a touch of curry and spices, cooked in coconut milk and topped with roasted peanuts and fresh coriander (cilantro). Scrumptious! Serve hot or at room temperature, on it\\'s own or as a side to satay chicken or vegetarian cuisine. Inspired by a Zatarain\\'s recipe. Note: This is not an overly hot and spicy dish, as written, but very delicious. We like it light to medium spicy so the other ingredients\\' delicate flavors aren\\'t lost in the heat; it\\'s just a matter of taste. If you like more heat and spice, adjust the seasonings as needed (you can use hot madras curry, and hot peppers for the mild ones). Enjoy!\\nImages: c(\"https://img.sndimg.com/food/image/upload/w_555,h_416,c_fit,fl_progressive,q_95/v1/img/recipes/45/53/03/pic8r1r42.jpg\", \"https://img.sndimg.com/food/image/upload/w_555,h_416,c_fit,fl_progressive,q_95/v1/img/recipes/45/53/03/pic8Ga91L.jpg\", \"https://img.sndimg.com/food/image/upload/w_555,h_416,c_fit,fl_progressive,q_95/v1/img/recipes/45/53/03/picTQF604.jpg\")\\nRecipeCategory: Rice\\nKeywords: c(\"Indian\", \"Kid Friendly\", \"Weeknight\", \"< 30 Mins\", \"Easy\", \"From Scratch\")\\nRecipeIngredientQuantities: c(\"2\", \"2\", \"2\", \"1/4\", \"1\", \"1\", \"1/3\", \"1/3\", \"1/2\", \"1/2\", \"1\", \"1\", \"1\", \"1/4\", \"1 -2\", \"1\")\\nRecipeIngredientParts: c(\"butter\", \"curry powder\", \"sugar\", \"turmeric\", \"garlic powder\", \"onion powder\", \"red bell pepper\", \"green bell pepper\", \"molasses\", \"water\", \"light coconut milk\", \"roasted peanuts\", \"fresh cilantro\", \"lime\")\\nAggregatedRating: 4\\nReviewCount: 1\\nCalories: 331.6\\nFatContent: 13.3\\nSaturatedFatContent: 4.7\\nCholesterolContent: 15.3\\nSodiumContent: 176.1\\nCarbohydrateContent: 47.5\\nFiberContent: 3.8\\nSugarContent: 4.3\\nProteinContent: 7.1\\nRecipeServings: NA\\nRecipeYield: NA\\nRecipeInstructions: c(\"Melt butter in medium saucepan on medium heat. Add curry powder and sugar; cook and stir 30 seconds.\", \"Pour water and coconut milk into saucepan. Bring to boil. Stir in rice, turmeric, garlic, onion, chicken base (or salt), and molasses; return to boil.\", \"Reduce heat to low; cover and simmer 15-20 minutes or until rice is tender (add diced red and green bell pepper the last 5 minutes of cooking).\", \"Remove from heat. Let stand 5 minutes, then fluff rice with a fork and serve topped with roast peanuts, snipped coriander, and fresh lime wedges.\", \\n\"May be served hot or at room temperature.\")\\nRecipeId: 123776\\nName: South Indian Coconut Rice\\nAuthorId: 83400\\nAuthorName: Daydream\\nCookTime: PT30M\\nPrepTime: PT20M\\nTotalTime: PT50M\\nDatePublished: 2005-05-26T22:22:00Z\\nDescription: Lovely with curries, particularly sea-food, this rice dish from Tamil Nadu is seasoned with lightly roasted coconut, cilantro, curry leaves, dried red chillies, and mustard seeds. It also contains a small amount of chana dal and urad dal, which, when roasted, provide a nutty taste and texture. If you cannot obtain fresh coconut, soak 1 1/4 cups of unsweetened, desiccated coconut in warm water (to barely cover) for 1 hour then drain and squeeze dry.\\nImages: character(0)\\nRecipeCategory: Curries\\nKeywords: c(\"Rice\", \"Coconut\", \"Fruit\", \"Nuts\", \"Asian\", \"Indian\", \"< 60 Mins\", \"Stove Top\")\\nRecipeIngredientQuantities: c(\"2\", \"3\", \"6\", \"1 1/2\", \"1 1/2\", \"1\", \"15\", \"1\", \"1/4\", \"1 3/4\", \"2\")\\nRecipeIngredientParts: c(\"basmati rice\", \"coconut oil\", \"channa dal\", \"Urad Dal\", \"brown mustard seeds\", \"curry leaves\", \"salt\", \"asafoetida powder\", \"coconut\", \"fresh cilantro\")\\nAggregatedRating: 4.5\\nReviewCount: 3\\nCalories: 716.8\\nFatContent: 37.5\\nSaturatedFatContent: 30.7\\nCholesterolContent: 0\\nSodiumContent: 608.5\\nCarbohydrateContent: 88.2\\nFiberContent: 11.1\\nSugarContent: 7.3\\nProteinContent: 12\\nRecipeServings: 4\\nRecipeYield: NA\\nRecipeInstructions: c(\"Wash the rice well and cook until tender in a rice cooker or by the absorption method.\", \"While the rice is cooking, heat 3 tablespoons oil in a medium-sized pan or skillet, and when hot add the chillies, chana dal, urad dal and mustard seeds. Stir and fry until the chillies darken and the dals turn golden brown.\", \"Add the curry leaves, salt, asafetida and coconut, and stir and fry for a minute or two before reducing heat.\", \"Gently cook the coconut mixture until the coconut turns a toasted reddish-brown and becomes quite crisp. It burns easily, so don\\'t take your eyes off it for a second, and keep the coconut moving by stirring and tossing constantly.\", \\n\"As soon as the coconut is the right colour and texture, turn off the heat. If the rice is not ready, transfer the coconut mixture to a bowl, so that it doesn\\'t continue browning in the hot pan.\", \"Mix the coconut mixture gently through the hot, cooked rice, then stir through the chopped cilantro and serve immediately.\")\\nRecipeId: 144250\\nName: Thai Ginger Coconut Vegetable Toss\\nAuthorId: 257506\\nAuthorName: aerobicon\\nCookTime: NA\\nPrepTime: PT15M\\nTotalTime: PT15M\\nDatePublished: 2005-11-07T22:20:00Z\\nDescription: Delicious dish. Not spicy at all, but you can add more spice if you wish. I served it over brown rice, but feel free to serve it over white rice, noodles, or plain - but if you eat it plain I suggest less water.\\nImages: c(\"https://img.sndimg.com/food/image/upload/w_555,h_416,c_fit,fl_progressive,q_95/v1/img/recipes/14/42/50/picrHXFCp.jpg\", \"https://img.sndimg.com/food/image/upload/w_555,h_416,c_fit,fl_progressive,q_95/v1/img/recipes/14/42/50/picGcCoKE.jpg\")\\nRecipeCategory: One Dish Meal\\nKeywords: c(\"Coconut\", \"Cauliflower\", \"Peppers\", \"Fruit\", \"Vegetable\", \"Nuts\", \"Thai\", \"Asian\", \"Lactose Free\", \"Low Protein\", \"Vegan\", \"Free Of...\", \"< 15 Mins\")\\nRecipeIngredientQuantities: c(\"2\", \"1\", \"2\", \"1/2\", \"1/2\", \"1/2\", \"1/2\", \"1\", \"1/2\", \"1/2\", \"1/2\", \"1/2\", \"1/8 - 1/4\")\\nRecipeIngredientParts: c(\"ginger\", \"cauliflower\", \"carrot\", \"bell pepper\", \"peas\", \"coconut milk\", \"salt\", \"black pepper\", \"turmeric\", \"chili powder\", \"paprika\", \"lime juice\")\\nAggregatedRating: 4.5\\nReviewCount: 3\\nCalories: 215\\nFatContent: 9.9\\nSaturatedFatContent: 6.4\\nCholesterolContent: 0\\nSodiumContent: 629.5\\nCarbohydrateContent: 30.5\\nFiberContent: 3.7\\nSugarContent: 22.6\\nProteinContent: 3.2\\nRecipeServings: 4\\nRecipeYield: NA\\nRecipeInstructions: c(\"Saute ginger in sesame oil over medium-high heat.\", \"Add in cauliflower, carrots, peppers, spices, lime juice, and a bit of water. Toss well.\", \"Once liquid starts bubbling, cover and simmer for about 5-7 minutes. Give another stir, and at this point your vegetables should be getting tender.\", \"You should also add in about another quarter cup or less of water. Simmer for a few minutes, then check to see if vegetables are tender.\", \"If they aren\\'t, let simmer until they are. If they are, turn heat to very low and add peas. Cover, stir, and let sit for five minutes. Serve over rice or noodles, if you\\'d like.\"\\n)\\nRecipeId: 244080\\nName: The Parker\\'s Coconut Rice\\nAuthorId: 550996\\nAuthorName: The Parker\\nCookTime: PT20M\\nPrepTime: PT2M\\nTotalTime: PT22M\\nDatePublished: 2007-08-02T20:28:00Z\\nDescription: I am asked to make this more often than I\\'d like.  It\\'s so simple and bland, yet so surprisingly different and refreshing.  If something has a bit of spicy heat to it, this is a way to balance the meal.\\nImages: character(0)\\nRecipeCategory: Coconut\\nKeywords: c(\"Fruit\", \"Nuts\", \"Low Protein\", \"< 30 Mins\", \"Easy\")\\nRecipeIngredientQuantities: c(\"1\", \"1\", \"1\", \"1/2\", \"1/4\")\\nRecipeIngredientParts: c(\"unsweetened coconut milk\", \"water\", \"long-grain rice\", \"salt\", \"basil\", \"cilantro\")\\nAggregatedRating: NA\\nReviewCount: NA\\nCalories: 372.7\\nFatContent: 22.3\\nSaturatedFatContent: 19.5\\nCholesterolContent: 0\\nSodiumContent: 309.6\\nCarbohydrateContent: 40.1\\nFiberContent: 0.7\\nSugarContent: 0.1\\nProteinContent: 5.5\\nRecipeServings: NA\\nRecipeYield: NA\\nRecipeInstructions: c(\"Bring coconut milk and water to a boil with rice.  Simmer, covered, about 20 minutes, stirring only 2 or 3 times until most of the liquid is absorbed.\", \"Keep covered until ready to serve and stir in the herb you have chosen.\")', name='retrieve_culinary_context', id='e64573a7-e78e-400e-aca7-088abe52b503', tool_call_id='call_FWe3tDCKPwc8PVAzFnQkSLya'), AIMessage(content='[India], [South]', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 3033, 'total_tokens': 3041, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-CjN9814aJDfTyyKZ1OuluZk2qU9Ew', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--7b694c58-5ae4-473c-b9fc-540facc99820-0', usage_metadata={'input_tokens': 3033, 'output_tokens': 8, 'total_tokens': 3041, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "result = culinary_detective.invoke({\n",
    "    \"messages\": culinary_detective_messages + [\n",
    "        {\"role\": \"human\", \"content\": \"The dish is spicy, coconut-based, and served with rice.\"}\n",
    "    ]\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e6a54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_culinary_detective_answer(response: str) -> tuple[str, str]:\n",
    "    # TODO: Extract the country and region from the response\n",
    "    # return country, region\n",
    "    import re\n",
    "    \n",
    "    # Look for pattern [country], [region] or variations\n",
    "    bracket_pattern = r'\\[([^\\]]+)\\]\\s*,\\s*\\[([^\\]]+)\\]'\n",
    "    match = re.search(bracket_pattern, response)\n",
    "    \n",
    "    if match:\n",
    "        country = match.group(1).strip()\n",
    "        region = match.group(2).strip()\n",
    "        return country, region\n",
    "    \n",
    "    # Fallback: look for two items separated by comma\n",
    "    lines = response.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        # Skip lines that are too long (likely explanations)\n",
    "        if len(line) > 100:\n",
    "            continue\n",
    "        # Look for comma-separated values\n",
    "        if ',' in line:\n",
    "            parts = line.split(',')\n",
    "            if len(parts) >= 2:\n",
    "                country = parts[0].strip().strip('[]\"\\'')\n",
    "                region = parts[1].strip().strip('[]\"\\'')\n",
    "                # Clean up common prefixes\n",
    "                for prefix in ['The answer is', 'Answer:', 'Country:', 'Region:']:\n",
    "                    country = country.replace(prefix, '').strip()\n",
    "                    region = region.replace(prefix, '').strip()\n",
    "                return country, region\n",
    "    \n",
    "    # Last resort: return empty strings\n",
    "    return \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9400a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_culinary_detective_answer(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86672811",
   "metadata": {},
   "source": [
    "### ðŸ‘„Lingua Locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ad20b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingua_locale_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"\n",
    "You are an expert in languages, scripts, orthography, and regional vocabulary. Determine which country's website or text a sentence most likely comes from.\n",
    "\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"\n",
    "Return ONLY a single line: [Country]\n",
    "- Use the full official country name (e.g., \"United States\", not \"USA\").\n",
    "- No explanations. Do not output anything else.\n",
    "\n",
    "Heuristics:\n",
    "- English: colour, organise, centre â†’ [United Kingdom]; sidewalk, color, organize â†’ [United States].\n",
    "- Portuguese: autocarro, factura, telemÃ³vel â†’ [Portugal]; Ã´nibus, nota fiscal, celular â†’ [Brazil].\n",
    "- Spanish: vos, colectivo, pileta â†’ [Argentina]; ordenador â†’ [Spain]; autobÃºs â†’ [Mexico/Spain], coche (Spain) vs carro (LatAm).\n",
    "- Chinese: Traditional characters (è‡ºç£ã€è‡ºåŒ—ã€ç¹é«”) â†’ [Taiwan]; Simplified (ä¸­å›½ã€å¹¿å·žã€ç®€ä½“) â†’ [China].\n",
    "- Cyrillic specifics: Ð´Ñ˜ / Ñ’ / Ñ› / Ñ™ / Ñš â†’ [Montenegro]; Ð´ÐµÐ²Ð¾Ñ˜ÐºÐ° / Ñ’Ð°Ðº more typical of [Serbia].\n",
    "- French: anglicisms + CAD context â†’ [Canada]; mÃ©tropolitain cues â†’ [France].\n",
    "- Haitian Creole â†’ [Haiti].\n",
    "\n",
    "Examples:\n",
    "Input: \"Please, colour is the preferred spelling in our centre.\"\n",
    "Output: [United Kingdom]\n",
    "\n",
    "Input: \"Clique para imprimir a fatura no seu telemÃ³vel.\"\n",
    "Output: [Portugal]\n",
    "\n",
    "Input: \"Ð¡Ð¸Ð½Ð¾Ñ› ÑÐ°Ð¼ Ð²Ð¸Ð´Ð¸Ð¾ Ð´Ñ˜ÐµÐ²Ð¾Ñ˜ÐºÑƒ Ñƒ ÐŸÐ¾Ð´Ð³Ð¾Ñ€Ð¸Ñ†Ð¸.\"\n",
    "Output: [Montenegro]\n",
    "\n",
    "Input: \"é€™æ˜¯è‡ºç£æœ¬åœ°çš„é é¢ã€‚\"\n",
    "Output: [Taiwan]\n",
    "\n",
    "Now produce ONLY [Country] for the current sentence.\n",
    "\"\"\"},\n",
    "]\n",
    "\n",
    "lingua_locale = create_agent(model=llm, tools=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5da2a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lingua_locale_answer(response: str) -> tuple[str, str]:\n",
    "    # TODO: Extract the country and \"none\" from the response\n",
    "    # only the first field is used, the second is a dummy field to make the return type consistent\n",
    "    # return country, \"none\"\n",
    "    import re\n",
    "    \n",
    "    # Look for pattern [country] in brackets\n",
    "    bracket_pattern = r'\\[([^\\]]+)\\]'\n",
    "    match = re.search(bracket_pattern, response)\n",
    "    \n",
    "    if match:\n",
    "        country = match.group(1).strip()\n",
    "        return country, \"none\"\n",
    "    \n",
    "    # Fallback: look for country name in response\n",
    "    lines = response.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        # Skip lines that are too long (likely explanations)\n",
    "        if len(line) > 100:\n",
    "            continue\n",
    "        # Clean the line\n",
    "        clean_line = line.strip().strip('[]\"\\'')\n",
    "        # Remove common prefixes\n",
    "        for prefix in ['The answer is', 'Answer:', 'Country:', 'The country is', 'This is from']:\n",
    "            clean_line = clean_line.replace(prefix, '').strip()\n",
    "        \n",
    "        # If we have a short, cleaned line, it's likely the country\n",
    "        if clean_line and len(clean_line) < 50:\n",
    "            # Remove any trailing punctuation\n",
    "            clean_line = clean_line.rstrip('.,;:')\n",
    "            return clean_line, \"none\"\n",
    "    \n",
    "    # Last resort: return empty string\n",
    "    return \"\", \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3291f",
   "metadata": {},
   "source": [
    "## Answering questions\n",
    "This part includes how we load the questions and generate the prediction in desired format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59f9861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geoguesser(q: dict, print_raw_response=False) -> tuple[str, str]:\n",
    "    if q[\"type\"] == \"GlobalTrekker\":\n",
    "        query = {\"role\": \"user\", \"content\": f\"Paragraph: {q['paragraph']}\"}\n",
    "        messages, agent, extractor = global_trekker_messages, global_trekker, extract_global_trekker_answer\n",
    "    elif q[\"type\"] == \"CulinaryDetective\":\n",
    "        query = {\"role\": \"user\", \"content\": f\"Ingredients: {q['ingredient']}. Description: {q['description']}\"}\n",
    "        messages, agent, extractor = culinary_detective_messages, culinary_detective, extract_culinary_detective_answer\n",
    "    else: #q[\"type\"] == \"LinguaLocale\":\n",
    "        query = {\"role\": \"user\", \"content\": f\"Sentence: {q['sentence']}\"}\n",
    "        messages, agent, extractor = lingua_locale_messages, lingua_locale, extract_lingua_locale_answer\n",
    "\n",
    "    response_all = agent.invoke({\"messages\": messages + [query]})\n",
    "    response = response_all[\"messages\"][-1].content\n",
    "    if print_raw_response: print(f\"{q['type']}: {response_all}\")\n",
    "    return extractor(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45950e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Here, we load the examples questions. Public/private set will be in the same format\n",
    "dataset_name = \"public.jsonl\"\n",
    "questions = []\n",
    "with open(dataset_name, \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        questions.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14091132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalTrekker: {'messages': [SystemMessage(content='You are an expert in world geography and cultural geography. Given a descriptive paragraph, infer the most likely country and city with high precision.', additional_kwargs={}, response_metadata={}, id='9d43451f-58fa-47a5-b701-cf449952dd8a'), HumanMessage(content='\\nRead the paragraph and extract:\\n- Country: use the full official country name (e.g., \"United States\", not \"USA\").\\n- City: a specific city if clearly indicated by clues (landmarks, neighborhoods, transit lines, local foods, dialects). If not identifiable, write \"Unknown\".\\n\\nStrict output format (no explanations):\\n[Country], [City]\\n\\nGuidelines:\\n- Prefer unique cues (local transit names, street names, postal formats, phone codes, currency, cuisine, sports clubs).\\n- If multiple cities fit, pick the single most likely one.\\n- If the paragraph is generic or only country-level, return \"Unknown\" for city.\\n- Do not include any extra text besides the bracketed pair.\\n\\nExamples:\\nInput: \"We walked along the Arno past the Ponte Vecchio before climbing to Piazzale Michelangelo.\"\\nOutput: [Italy], [Florence]\\n\\nInput: \"A red double-decker bus passed by the Thames near Westminster Abbey and Big Ben.\"\\nOutput: [United Kingdom], [London]\\n\\nInput: \"We grabbed Primanti\\'s near the confluence of the Allegheny and Monongahela.\"\\nOutput: [United States], [Pittsburgh]\\n\\nInput: \"I toured the Old Town and the Royal Mile before seeing the castle on the hill.\"\\nOutput: [United Kingdom], [Edinburgh]\\n\\nInput: \"We enjoyed maple syrup and poutine while skating on a canal in winter.\"\\nOutput: [Canada], [Ottawa]\\n', additional_kwargs={}, response_metadata={}, id='9ef9139d-e069-48c5-8989-c1548ee6f9e6'), HumanMessage(content='Paragraph: Uluru, also known as Ayers Rock, is a large sandstone monolith that is sacred to the Pitjantjatjara, the Aboriginal people of the area, known as the Aá¹‰angu. It is one of the most important indigenous sites of the country, being a popular destination for tourists since the 1930s. The area around the formation is home to many springs, waterholes, rock caves and ancient paintings. Uluru is listed as a UNESCO World Heritage Site.', additional_kwargs={}, response_metadata={}, id='ba9f9a22-fe02-4403-8c7b-03a132655d3a'), AIMessage(content='[Australia], [Unknown]', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 442, 'total_tokens': 450, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-CjN9AD99QE3qn63gnpYrVB7WeoXtj', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f2953f74-d5f7-4148-8951-65c9c4f3c2ac-0', usage_metadata={'input_tokens': 442, 'output_tokens': 8, 'total_tokens': 450, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Australia', 'Unknown')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test run on one question\n",
    "# You might want to save the raw response for debugging answer formatting/extraction\n",
    "# If the extracted answer seems off, check the raw response instead of running inference repeatedly\n",
    "geoguesser(questions[0], print_raw_response=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "339601c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [05:58<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to public.txt (private set)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample script to generate answers\n",
    "from tqdm import tqdm\n",
    "answers = []\n",
    "for q in tqdm(questions):\n",
    "    try:\n",
    "        country, category = geoguesser(q)\n",
    "        answers.append(f\"{q['type']}\\t{country}\\t{category}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question {q}: {e}\")\n",
    "        answers.append(f\"{q['type']}\\tUnknown\\tUnknown\")\n",
    "\n",
    "with open(\"public.txt\", \"w\") as f:\n",
    "    for answer in answers:\n",
    "        f.write(answer + \"\\n\")\n",
    "\n",
    "print(\"Saved predictions to public.txt (private set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99774c89",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "This is how we calculate the scores on Gradescope (details subject to change, but the general logic will stay the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e478646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_match(answer, expectedAnswer):\n",
    "    score = 0.0\n",
    "    if expectedAnswer in answer:\n",
    "        score = len(expectedAnswer) / len(answer)\n",
    "    return score\n",
    "\n",
    "def exact_match(answer, expectedAnswer):\n",
    "    score = 0.0\n",
    "    if expectedAnswer == answer:\n",
    "        score = 1.0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f16b03ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalTrekker Average Score: 0.7229\n",
      "CulinaryDetective Average Score: 0.3055\n",
      "LinguaLocale Average Score: 0.8852\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for q in questions:\n",
    "    answers.append((q[\"type\"], q[\"country\"], q.get(\"city\", q.get(\"region\", \"\"))))\n",
    "with open(\"public.txt\", \"r\") as f:\n",
    "    preds = [line.split(\"\\t\") for line in f.readlines()]\n",
    "\n",
    "scores = {\"GlobalTrekker\": [], \"CulinaryDetective\": [], \"LinguaLocale\": []}\n",
    "for (q_type, exp_country, exp_place), (p_type, pred_country, pred_place) in zip(answers, preds):\n",
    "    assert q_type == p_type\n",
    "    country_score = soft_match(pred_country, exp_country)\n",
    "    category_score = 0.0\n",
    "    weights = [0.0, 0.0]\n",
    "    if q_type == \"GlobalTrekker\":\n",
    "        #  correct country -> 80%, correct country and city -> +20%\n",
    "        weights = [0.8, 0.2]\n",
    "        if country_score > 0:\n",
    "            if exp_place == \"None\": category_score = 1.0\n",
    "            else: category_score = soft_match(pred_place, exp_place)\n",
    "    elif q_type == \"CulinaryDetective\":\n",
    "        # correct country -> 60%, correct country and region -> +40%\n",
    "        weights = [0.6, 0.4]\n",
    "        if country_score > 0:\n",
    "            if exp_place == \"None\": category_score = 1.0\n",
    "            else: category_score = exact_match(pred_place, exp_place)\n",
    "    else: # LinguaLocale\n",
    "        # correct country -> 60%, matched official language -> +40%\n",
    "        weights = [0.6, 0.4]\n",
    "        if country_score > 0:\n",
    "            category_score = 1.0\n",
    "        else: # incorrect country. language match works only if pred_country is a clean answer\n",
    "            exp_langs = list_of_countries.get(exp_country, [])\n",
    "            pred_langs = list_of_countries.get(pred_country, [])\n",
    "            if any(lang in exp_langs for lang in pred_langs):\n",
    "                category_score = 1.0\n",
    "\n",
    "    score = weights[0] * country_score + weights[1] * category_score\n",
    "    scores[q_type].append(score)\n",
    "\n",
    "for q_type, score_list in scores.items():\n",
    "    avg_score = sum(score_list) / len(score_list)\n",
    "    print(f\"{q_type} Average Score: {avg_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Universal Environment",
   "language": "python",
   "name": "ml-universal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
